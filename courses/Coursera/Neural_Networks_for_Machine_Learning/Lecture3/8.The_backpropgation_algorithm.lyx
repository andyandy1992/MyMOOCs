#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\begin_modules
theorems-ams-bytype
theorems-sec-bytype
theorems-ams-extended-bytype
eqs-within-sections
figs-within-sections
tabs-within-sections
\end_modules
\maintain_unincluded_children false
\language british
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format pdf2
\output_sync 0
\bibtex_command default
\index_command default
\float_placement H
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 2cm
\rightmargin 2cm
\bottommargin 2cm
\headheight 1cm
\headsep 1cm
\footskip 1cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle fancy
\tracking_changes false
\output_changes false
\html_math_output 3
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
setcounter{section}{7}
\end_layout

\end_inset


\end_layout

\begin_layout Section
The backpropagation algorithm
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Abstract
Th backpropagation algorithm developed during the 1980s led to an explosion
 of interest in neural networks.
 It allows us to learn multiple layers of features.
 Networks without hidden units are very limited in the input-output mappings
 they can model.
 Adding a layer of hand-coded features (as in a perceptron) makes them much
 more powerful, but the hard bit is designing the features.
 To find good features without requiring insight into the task or repeated
 trial and error, we use this as an automate the process of designing features
 for a particular task, and seeing how well they work.
 In particular, if you come up with a way to measure error of a network,
 backpropagation tells you how to change the weights to most efficiently
 minimise that error (or the error gradient in technical terms).
\end_layout

\begin_layout Abstract
This chapter first describes very obvious algorithms that do not work nearly
 as well, but is something that many people think of when it comes to building
 system that learn.
 Now that we know how to learn the weights of the logistic units, we then
 return to the central issue, which is how to learn the weights of hidden
 units (they are called hidden units because nobody is telling us what their
 states ought to be).
\end_layout

\begin_layout Subsection
Inefficient methods: learning by randomly perturbing weights (c.f.
 evolution)
\end_layout

\begin_layout Standard
Consider the following methods (based on intuition/those who understand
 evolution); these are forms of reinforcement learning.
\end_layout

\begin_layout Subsubsection
Randomly perturb one weight, and see if it improves performance - if so,
 save the change.
\end_layout

\begin_layout Standard
This is 
\bar under
very inefficient
\bar default
 (backpropagation is much better):
\end_layout

\begin_layout Itemize
We need to do multiple forward passes on a representative set of training
 cases just to change one weight.
 
\end_layout

\begin_layout Itemize
Towards the end of learning, large weight perturbations will nearly always
 make things worse, because the weights need to have the right relative
 values.
\end_layout

\begin_layout Subsubsection
Learning by randomly perturbing all weights in parallel, and correlate the
 performance gain with the weight changes
\end_layout

\begin_layout Standard
This is not any better:
\end_layout

\begin_layout Itemize
We need lots of trials on each training case to 
\begin_inset Quotes eld
\end_inset

see
\begin_inset Quotes erd
\end_inset

 the effect of changing one weight through the noise created by all the
 changes to other weights.
\end_layout

\begin_layout Subsubsection
Learning by randomly perturbing the activities of the hidden units.
\end_layout

\begin_layout Standard
Once we know how we want a hidden activity to change on a given training
 case, we can compute how to change the weights:
\end_layout

\begin_layout Itemize
There are fewer activities than weights, but backpropagation still wins
 by a factor of the number of neurons.
\end_layout

\begin_layout Subsection
The idea behind backpropagation
\end_layout

\begin_layout Itemize
We do not know what the hidden units ought to do (hence the name 
\begin_inset Quotes eld
\end_inset

hidden
\begin_inset Quotes erd
\end_inset

), but we can compute how fast the error changes as we change a hidden activity.
\end_layout

\begin_layout Itemize
Instead of using desired activities to train the hidden units, we use error
 derivatives w.r.t.
 hidden activities.
\end_layout

\begin_deeper
\begin_layout Itemize
Each hidden activity can affect many output units and can therefore have
 many separate effects on the error.
 These effects must be combined.
\end_layout

\begin_layout Itemize
We can compute error derivatives for all the hidden units efficiently at
 the same time.
 Once we have the error derivatives for the hidden activities, its easy
 to get the error derivatives for the weights going into a hidden unit.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
Step 2.
\begin_inset Graphics
	filename ../Images/Lecture3/Chapter8/backpropagation-single-case.png
	lyxscale 20
	scale 20

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
Step 3.
\begin_inset Graphics
	filename ../Images/Lecture3/Chapter8/backpropagating-algorithm.png
	lyxscale 20
	scale 20

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\series bold
Sketch of the backpropagation algorithm on a single case
\series default
:
\begin_inset Newline newline
\end_inset

1.
 Convert the error between actual output and target output into an error
 derivative (e.g.
 using usual error 
\begin_inset Formula $E=\frac{1}{2}\sum_{j\in\mbox{output}}\left(t_{j}-y_{j}\right)^{2}\Rightarrow\frac{\partial E}{\partial y_{j}}=-\left(t_{j}-y_{j}\right)$
\end_inset

).
\begin_inset Newline newline
\end_inset

2.
 Compute error derivatives in each hidden layer from error derivatives in
 the layer above.
\begin_inset Newline newline
\end_inset

3.
 Use these error derivatives w.r.t.
 activities to get error derivatives w.r.t.
 the incoming weights.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Using the derivatives computed by backpropagation
\end_layout

\begin_layout Standard
Figuring out how to obtain the error derivatives for all the weights in
 a multilayer network is the key to being able to learn efficient neural
 networks.
 The backprogation algorithm is an efficient way of computing the error
 derivative 
\begin_inset Formula $\frac{dE}{dw}$
\end_inset

 for every weight on a single training case.
 To get a fully specified learning procedure, we still need to make a lot
 of other decisions:
\end_layout

\begin_layout Itemize
How to prevent the network from over-fitting very badly if we use a large
 network?
\end_layout

\begin_layout Itemize
How to use the error derivatives found by backpropagation:
\end_layout

\begin_deeper
\begin_layout Itemize

\emph on
Optimisation issues (more detail at section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Optimisation-issues"

\end_inset

): 
\emph default
How do we use the error derivative on individual cases to discover a good
 set of weights?
\end_layout

\begin_layout Itemize

\emph on
Generalisation issues (more detail at section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Generalisation-issues"

\end_inset

):
\emph default
 How do we ensure that the learned weights work well for cases we did not
 see during training?
\end_layout

\end_deeper
\begin_layout Subsubsection
Over-fitting: The downside of using powerful models
\end_layout

\begin_layout Standard
The training data contains information about the 
\emph on
regularities 
\emph default
in the mapping from input to output, but it also contains two types of noise:
\end_layout

\begin_layout Itemize

\emph on
Unreliable target values.
\end_layout

\begin_layout Itemize

\emph on
Sampling error: 
\emph default
there will be accidental regularities just because of the particular training
 cases that chosen; e.g.
 if a teacher explains what polygons are by showing a square and a rectangle,
 you'll not know that polygons do not only have 4 sides, right angles etc.
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

For any finite set of examples, there'll be accidental regularities.
\begin_inset Quotes erd
\end_inset

 When fitting models, there's no way it can tell the difference between
 an accidental regularity that's just there because of the particular sample
 we chose, and real regularities that'll generalise properly to new cases.
\end_layout

\begin_layout Itemize
So if the model is very flexible, it can model the sampling error really
 well - this is a disaster!
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /home/andyandy/Desktop/Git/MyMOOCs/courses/Coursera/Neural_Networks_for_Machine_Learning/Images/Lecture3/Chapter8/overfitting.png
	lyxscale 20
	scale 20

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\series bold
An example of over-fitting:
\series default
 Which model should we use? 
\color red
The complicated model fits the data better, but it's not economical.
 
\color inherit
A model is convincing when it fits a 
\emph on
lot of data 
\emph default
surprisingly well.
 (It is not surprising that a complicated model can fit a small amount of
 data well, as above.)
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Reducing over-fitting
\end_layout

\begin_layout Standard
A large number of different methods have been developed (see lecture 7 ,
 section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Generalisation-issues"

\end_inset

 for more explanation):
\end_layout

\begin_layout Description
Weight-decay Keep the model simple by keeping the weights as small as possible
 (or even zero).
\end_layout

\begin_layout Description
Weight-sharing Insist many of the weights have exactly the same values as
 each other.
\end_layout

\begin_layout Description
Early
\begin_inset space ~
\end_inset

stopping Create 
\begin_inset Quotes eld
\end_inset

fake
\begin_inset Quotes erd
\end_inset

 test sets - every so often, look at what's happening on the fake test set
 (stop learning if fake test sets gets worse)
\end_layout

\begin_layout Description
Model
\begin_inset space ~
\end_inset

averaging Train on not so different NNs, and average them together in hope
 that it reduces the errors you're making.
\end_layout

\begin_layout Description
Bayesian
\begin_inset space ~
\end_inset

fitting Fancy form of model averaging.
\end_layout

\begin_layout Description
Dropout Make models more robust by randomly emitting hidden units upon learning.
\end_layout

\begin_layout Description
Generative
\begin_inset space ~
\end_inset

pre-training Complicated (see end of course).
\end_layout

\begin_layout Subsubsection
Optimisation issues in using the weight derivatives
\end_layout

\begin_layout Standard

\emph on
How often to update the weights?
\end_layout

\begin_layout Itemize

\bar under
Online
\bar default
 - after each training case.
\end_layout

\begin_layout Itemize

\bar under
Full Batch
\bar default
 - (
\begin_inset Quotes eld
\end_inset

more sensible
\begin_inset Quotes erd
\end_inset

) after a full sweep through the training data.
\end_layout

\begin_layout Itemize

\bar under
Mini-Batch
\bar default
 - (
\begin_inset Quotes eld
\end_inset

typically done when train big NNs on big data sets
\begin_inset Quotes erd
\end_inset

) after a small sample of training cases.
\end_layout

\begin_layout Standard

\emph on
How much to update?
\end_layout

\begin_layout Itemize
Use a fixed learning rate?
\end_layout

\begin_layout Itemize
Adapt the global learning rate? 
\end_layout

\begin_deeper
\begin_layout Itemize
If the error keeps going up and down (oscillating) then we'll reduce the
 learning rate, whilst if we're making steady progress, we'll increase the
 learning rate.
\end_layout

\end_deeper
\begin_layout Itemize
Adapt the learning rate on each connection separately?
\end_layout

\begin_layout Itemize
Don't use steepest descent at all?
\end_layout

\begin_deeper
\begin_layout Itemize
As we saw in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:6.3"

\end_inset

, steepest descent doesn't always converge quickly to the minimum.
\end_layout

\end_deeper
\end_body
\end_document
